{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 1: Data Loading and Cleaning\n",
    "\n",
    "Loading and cleaning the data upon first look.\n",
    "\n",
    "In this notebook, I will first define the purpose of this project where I discuss the reasons for doing my analysis. I then will begin the steps to loading and cleaning the data\n",
    "\n",
    "\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Notebook Contents__\n",
    "\n",
    "__1.1__ Introduction\n",
    "\n",
    "__1.1.1__ Workflow Diagram\n",
    "\n",
    "__1.2__ Loading Cleaning & Checking Data\n",
    "\n",
    "__1.3__ Investigating Columns\n",
    "\n",
    "__1.4__ Cleaning Text in Review Column\n",
    "\n",
    "__1.5__ Addressing Null Values\n",
    "\n",
    "__1.6__ Checking for Duplicates\n",
    "\n",
    "__1.7__ Correcting Data Types\n",
    "\n",
    "__1.8__ Feature Creation\n",
    "\n",
    "__1.9__ Saving Work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.1 Introduction__\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "As of July 2023, the global size of the airline industry is estimated at a whopping $841.5bn, a 7% increase from the year before. Although one could argue that the industry is very stable due to the sheer demand from consumers, airlines could still use with improving customer satisfaction with the aim of becoming the favoured option in a highly saturated market.\n",
    "\n",
    "The problem at hand is to develop a data-driven solution to improve the quality of airline services and ultimately earn prospective airlines a good reputation in relation to their competitiors by analysing and extracting valuable insights from passenger reviews. Airlines receive an immeasurable volume of feedback from customers through various online platforms such as review websites and customer surveys. These reviews encompass a wide range of sentiments, including positive and negative feedback, some a bit too difficult to decipher. **We aim to produce an automated solution to decipher sentiment**.\n",
    "\n",
    "As mentioned earlier, this industry's stability is almost as similar to ones of other indutries such as commodities; so why would people leave reviews? good or bad? especially if they are more than likely to reuse these services, better yet - what experiences wow passengers so much that they would recommend the airline?\n",
    "\n",
    "___________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "The goal of this project is to explore the main pull factors that make a passenger's airline experience so great that not only would they leave a positive review but recommend the services to other curious researchers. I hope the conclusions drawn by the end of this project provides useful and actionable insights for airline managers on what levels of services are to be provided to receive a high rating score and benefit from word of mouth. This would especially help attract some new passengers, perhaps be in a better position competitvely, with the ultimate aim of being the most trusted and favoured airline.\n",
    "\n",
    "**Data Collection**\n",
    "\n",
    "The data used in this project was originally web-scraped from the Skytrax website, but later published on Kaggle by user `Efehan` titled, `Skytrax Airline Reviews`, and contains a large list of airline review scores along with the following attributes: airline, overall, author, review_date, customer_review, aircraft, traveller_type, cabin, date_flown, seat_comfort, cabin_service, food_bev, entertainment, ground_service, value_for_money, recommended. This dataset contains a mixture of both numeric and non-numeric data types.\n",
    "\n",
    "A direct download link to the dataset can be found [here](https://drive.google.com/uc?export=download&id=1ht8AOCyKsbBOb5ys58x5EU1f1do0yGRB):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.1.1 Workflow__\n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**\n",
    "\n",
    "These are the libraries required to load, clean and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.2 Loading, Cleaning & Checking Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Column Descriptions\n",
    "\n",
    "Before analysing the data, I want to take a quick look and explore the data and deal with any cleaning related issues accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data from my data folder\n",
    "airlinedf = pd.read_excel('/Users/faisal/BS_Capstone/capstone-project-fai22399-git/data/airline_reviews.xlsx', index_col=None, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>overall</th>\n",
       "      <th>author</th>\n",
       "      <th>review_date</th>\n",
       "      <th>customer_review</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>cabin</th>\n",
       "      <th>route</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_service</th>\n",
       "      <th>food_bev</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Christopher Hackley</td>\n",
       "      <td>8th May 2019</td>\n",
       "      <td>âœ… Trip Verified | London to Izmir via Istanb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London to Izmir via Istanbul</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Adriana Pisoi</td>\n",
       "      <td>7th May 2019</td>\n",
       "      <td>âœ… Trip Verified | Istanbul to Bucharest. We ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Istanbul to Bucharest</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airline  overall               author   review_date  \\\n",
       "0               NaN      NaN                  NaN           NaN   \n",
       "1  Turkish Airlines      7.0  Christopher Hackley  8th May 2019   \n",
       "2               NaN      NaN                  NaN           NaN   \n",
       "3  Turkish Airlines      2.0        Adriana Pisoi  7th May 2019   \n",
       "4               NaN      NaN                  NaN           NaN   \n",
       "\n",
       "                                     customer_review aircraft  traveller_type  \\\n",
       "0                                                NaN      NaN             NaN   \n",
       "1  âœ… Trip Verified | London to Izmir via Istanb...      NaN        Business   \n",
       "2                                                NaN      NaN             NaN   \n",
       "3  âœ… Trip Verified | Istanbul to Bucharest. We ...      NaN  Family Leisure   \n",
       "4                                                NaN      NaN             NaN   \n",
       "\n",
       "           cabin                         route           date_flown  \\\n",
       "0            NaN                           NaN                  NaN   \n",
       "1  Economy Class  London to Izmir via Istanbul  2019-05-01 00:00:00   \n",
       "2            NaN                           NaN                  NaN   \n",
       "3  Economy Class         Istanbul to Bucharest  2019-05-01 00:00:00   \n",
       "4            NaN                           NaN                  NaN   \n",
       "\n",
       "   seat_comfort  cabin_service  food_bev  entertainment  ground_service  \\\n",
       "0           NaN            NaN       NaN            NaN             NaN   \n",
       "1           4.0            5.0       4.0            4.0             2.0   \n",
       "2           NaN            NaN       NaN            NaN             NaN   \n",
       "3           4.0            1.0       1.0            1.0             1.0   \n",
       "4           NaN            NaN       NaN            NaN             NaN   \n",
       "\n",
       "   value_for_money recommended  \n",
       "0              NaN         NaN  \n",
       "1              4.0         yes  \n",
       "2              NaN         NaN  \n",
       "3              1.0          no  \n",
       "4              NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if data has been read in by viewing the first 5 rows\n",
    "airlinedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, I can notice a pattern whereby every other row is filled with completely `NaN` values. I will look further into the dataset to confirm this early finding and then deal with it accordingly, perhaps by dropping null rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (131895, 17)\n"
     ]
    }
   ],
   "source": [
    "#Returns the shape of the DataFrame\n",
    "print(f\"Shape of DataFrame: {airlinedf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airline',\n",
       " 'overall',\n",
       " 'author',\n",
       " 'review_date',\n",
       " 'customer_review',\n",
       " 'aircraft',\n",
       " 'traveller_type',\n",
       " 'cabin',\n",
       " 'route',\n",
       " 'date_flown',\n",
       " 'seat_comfort',\n",
       " 'cabin_service',\n",
       " 'food_bev',\n",
       " 'entertainment',\n",
       " 'ground_service',\n",
       " 'value_for_money',\n",
       " 'recommended']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"List of Columns\")\n",
    "list(airlinedf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column Description:**\n",
    "\n",
    "`airline`: Name of the airline.\n",
    "\n",
    "`overall`: Overall point given to the trip between 1 to 10.\n",
    "\n",
    "`author`: Author of the trip(Passenger Name)\n",
    "\n",
    "`review_date`: Date of the Review\n",
    "\n",
    "`customer_review`: Review of the customers in free text format\n",
    "\n",
    "`aircraft`: Type of the aircraft\n",
    "\n",
    "`traveller_type`: Type of traveller (e.g. business, leisure)\n",
    "\n",
    "`cabin`: Cabin at the flight\n",
    "\n",
    "`date_flown`: Flight date\n",
    "\n",
    "__The following are categories that link to the overall satisfaction__:\n",
    "\n",
    "`seat_comfort`: Rated between 1-5\n",
    "\n",
    "`cabin_service`: Rated between 1-5\n",
    "\n",
    "`food_bev`: Rated between 1-5\n",
    "\n",
    "`entertainment`: Rated between 1-5\n",
    "\n",
    "`ground_service`: Rated between 1-5\n",
    "\n",
    "`value_for_money`: Rated between 1-5\n",
    "\n",
    "`recommended`: Binary, target variable. (yes,no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_service</th>\n",
       "      <th>food_bev</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64017.000000</td>\n",
       "      <td>60681.000000</td>\n",
       "      <td>60715.000000</td>\n",
       "      <td>52608.000000</td>\n",
       "      <td>44193.000000</td>\n",
       "      <td>39358.000000</td>\n",
       "      <td>63975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.145430</td>\n",
       "      <td>2.952160</td>\n",
       "      <td>3.191814</td>\n",
       "      <td>2.908170</td>\n",
       "      <td>2.863372</td>\n",
       "      <td>2.692820</td>\n",
       "      <td>2.943962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.477532</td>\n",
       "      <td>1.441362</td>\n",
       "      <td>1.565789</td>\n",
       "      <td>1.481893</td>\n",
       "      <td>1.507262</td>\n",
       "      <td>1.612215</td>\n",
       "      <td>1.587370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  seat_comfort  cabin_service      food_bev  entertainment  \\\n",
       "count  64017.000000  60681.000000   60715.000000  52608.000000   44193.000000   \n",
       "mean       5.145430      2.952160       3.191814      2.908170       2.863372   \n",
       "std        3.477532      1.441362       1.565789      1.481893       1.507262   \n",
       "min        1.000000      1.000000       1.000000      1.000000       1.000000   \n",
       "25%        1.000000      1.000000       2.000000      1.000000       1.000000   \n",
       "50%        5.000000      3.000000       3.000000      3.000000       3.000000   \n",
       "75%        9.000000      4.000000       5.000000      4.000000       4.000000   \n",
       "max       10.000000      5.000000       5.000000      5.000000       5.000000   \n",
       "\n",
       "       ground_service  value_for_money  \n",
       "count    39358.000000     63975.000000  \n",
       "mean         2.692820         2.943962  \n",
       "std          1.612215         1.587370  \n",
       "min          1.000000         1.000000  \n",
       "25%          1.000000         1.000000  \n",
       "50%          3.000000         3.000000  \n",
       "75%          4.000000         4.000000  \n",
       "max          5.000000         5.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlinedf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "\n",
    "We run a .describe() function to understand the numerical values within the dataset\n",
    "\n",
    "**Key Points**\n",
    "- The range of ratings for specific categories is from 1 to 5\n",
    "- The range of ratings for the overall is from 1 to 10\n",
    "- The average overall rating is 5.14, which naturally would be the case. \n",
    "\n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.3 Investigating Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131895 entries, 0 to 131894\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   airline          65947 non-null  object \n",
      " 1   overall          64017 non-null  float64\n",
      " 2   author           65947 non-null  object \n",
      " 3   review_date      65947 non-null  object \n",
      " 4   customer_review  65947 non-null  object \n",
      " 5   aircraft         19718 non-null  object \n",
      " 6   traveller_type   39755 non-null  object \n",
      " 7   cabin            63303 non-null  object \n",
      " 8   route            39726 non-null  object \n",
      " 9   date_flown       39633 non-null  object \n",
      " 10  seat_comfort     60681 non-null  float64\n",
      " 11  cabin_service    60715 non-null  float64\n",
      " 12  food_bev         52608 non-null  float64\n",
      " 13  entertainment    44193 non-null  float64\n",
      " 14  ground_service   39358 non-null  float64\n",
      " 15  value_for_money  63975 non-null  float64\n",
      " 16  recommended      64440 non-null  object \n",
      "dtypes: float64(7), object(10)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Get an overview of the dataset, how many null values are there?\n",
    "airlinedf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline             65948\n",
       "overall             67878\n",
       "author              65948\n",
       "review_date         65948\n",
       "customer_review     65948\n",
       "aircraft           112177\n",
       "traveller_type      92140\n",
       "cabin               68592\n",
       "route               92169\n",
       "date_flown          92262\n",
       "seat_comfort        71214\n",
       "cabin_service       71180\n",
       "food_bev            79287\n",
       "entertainment       87702\n",
       "ground_service      92537\n",
       "value_for_money     67920\n",
       "recommended         67455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of null values\n",
    "airlinedf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting discovery here... as mentioned earlier, it appeared that every other collumn was filled with `null` values. \n",
    "\n",
    "Now, I can see that the null values are almost identical to the non-null values from the `.info()` code block above. I can now be certain that there are double rows and can therefore drop the rows where all datapoints are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows where all data points are null using the how='all' condition\n",
    "cleandf = airlinedf.dropna(axis=0, how='all').copy().reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (65947, 17)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of the DataFrame\n",
    "print(f\"Shape of DataFrame: {cleandf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now see that the shape of the DataFrame has reduced massively from 131,895 rows to just 65,947 rows, which seems to correlate perfectly with the data in the `airline` and `customer_review` columns.\n",
    "\n",
    "This dataset is close to being cleaned and ready for analysis, however there are a few columns which still look like they are filled with too many null values for our likening. I will proceed to handle them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>overall</th>\n",
       "      <th>author</th>\n",
       "      <th>review_date</th>\n",
       "      <th>customer_review</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>cabin</th>\n",
       "      <th>route</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_service</th>\n",
       "      <th>food_bev</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Christopher Hackley</td>\n",
       "      <td>8th May 2019</td>\n",
       "      <td>âœ… Trip Verified | London to Izmir via Istanb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London to Izmir via Istanbul</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Adriana Pisoi</td>\n",
       "      <td>7th May 2019</td>\n",
       "      <td>âœ… Trip Verified | Istanbul to Bucharest. We ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Istanbul to Bucharest</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M Galerko</td>\n",
       "      <td>7th May 2019</td>\n",
       "      <td>âœ… Trip Verified | Rome to Prishtina via Ista...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Rome to Prishtina via Istanbul</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Zeshan Shah</td>\n",
       "      <td>6th May 2019</td>\n",
       "      <td>âœ… Trip Verified | Flew on Turkish Airlines I...</td>\n",
       "      <td>A330</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Washington Dulles to Karachi</td>\n",
       "      <td>April 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pooja Jain</td>\n",
       "      <td>6th May 2019</td>\n",
       "      <td>âœ… Trip Verified | Mumbai to Dublin via Istan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Mumbai to Dublin via Istanbul</td>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airline  overall               author   review_date  \\\n",
       "0  Turkish Airlines      7.0  Christopher Hackley  8th May 2019   \n",
       "1  Turkish Airlines      2.0        Adriana Pisoi  7th May 2019   \n",
       "2  Turkish Airlines      3.0            M Galerko  7th May 2019   \n",
       "3  Turkish Airlines     10.0          Zeshan Shah  6th May 2019   \n",
       "4  Turkish Airlines      1.0           Pooja Jain  6th May 2019   \n",
       "\n",
       "                                     customer_review aircraft  traveller_type  \\\n",
       "0  âœ… Trip Verified | London to Izmir via Istanb...      NaN        Business   \n",
       "1  âœ… Trip Verified | Istanbul to Bucharest. We ...      NaN  Family Leisure   \n",
       "2  âœ… Trip Verified | Rome to Prishtina via Ista...      NaN        Business   \n",
       "3  âœ… Trip Verified | Flew on Turkish Airlines I...     A330    Solo Leisure   \n",
       "4  âœ… Trip Verified | Mumbai to Dublin via Istan...      NaN    Solo Leisure   \n",
       "\n",
       "           cabin                           route           date_flown  \\\n",
       "0  Economy Class    London to Izmir via Istanbul  2019-05-01 00:00:00   \n",
       "1  Economy Class           Istanbul to Bucharest  2019-05-01 00:00:00   \n",
       "2  Economy Class  Rome to Prishtina via Istanbul  2019-05-01 00:00:00   \n",
       "3  Economy Class    Washington Dulles to Karachi           April 2019   \n",
       "4  Economy Class   Mumbai to Dublin via Istanbul  2019-05-01 00:00:00   \n",
       "\n",
       "   seat_comfort  cabin_service  food_bev  entertainment  ground_service  \\\n",
       "0           4.0            5.0       4.0            4.0             2.0   \n",
       "1           4.0            1.0       1.0            1.0             1.0   \n",
       "2           1.0            4.0       1.0            3.0             1.0   \n",
       "3           4.0            5.0       5.0            5.0             5.0   \n",
       "4           1.0            1.0       1.0            1.0             1.0   \n",
       "\n",
       "   value_for_money recommended  \n",
       "0              4.0         yes  \n",
       "1              1.0          no  \n",
       "2              2.0          no  \n",
       "3              5.0         yes  \n",
       "4              1.0          no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-load dataframe to view changes\n",
    "cleandf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.4 Cleaning Text in Review Column__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next observation of the data is that there are some odd characters at the beginning of each review, some sort of symbol perhaps an emoji, we will proceed to clean the text as we will end up with that characterised symbol as a highly impactive 'word' when it comes to our sentiment analysis.\n",
    "\n",
    "Another thing to mention is that at the begining of each review, the author has inputed their location of origin as well as their destination. In this specific case, this information will not be useful as at the point of modelling, it may just get an output saying the location is the highest positive/negative sentiment i.e. `london` as opposed to the real push and pull factors we are aiming to identify i.e. problems/praises regarding customer service. We will aim to sort this out during our preprocessing stage before modelling.\n",
    "\n",
    "Upon further inspection, we notice that a large number of reviews have a prefix along the lines of `verified review`, we would want to remove these as part of the text cleaning to ensure no bias in the data. Given the fact that this prefix would appear in majority of reviews, at the stage of modelling, this would appear as an influential indicator of our sentiment analysis. In our use case, this provides no context whatsoever to the inference problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clean text\n",
    "def cleanedtext(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.lstrip(\"âœ verified review\").lstrip(\"verified review\").lstrip(\"âœ trip\").lstrip('verified').lstrip(\" trip verified\").lstrip(\"... verified review\")\n",
    "    return text\n",
    "\n",
    "cleandf['customer_review'] = cleandf['customer_review'].apply(cleanedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27048    have not flown china southern for many years d...\n",
       "20879    seoul gimpo to jeju  the flight that i booked ...\n",
       "56945    booking was easy and transparent  paid 168â   ...\n",
       "54785    lauderdale to baltimore with spirit airlines  ...\n",
       "2083     stockholm to doha with qatar airways  sas grou...\n",
       "Name: customer_review, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check function output\n",
    "cleandf['customer_review'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not be the cleanest of data with regards to grammatical errors, however, it is suitable enough to proceed. \n",
    "\n",
    "\n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.5 Addressing Null Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airline             0.00\n",
       "overall             2.93\n",
       "author              0.00\n",
       "review_date         0.00\n",
       "customer_review     0.00\n",
       "aircraft           70.10\n",
       "traveller_type     39.72\n",
       "cabin               4.01\n",
       "route              39.76\n",
       "date_flown         39.90\n",
       "seat_comfort        7.99\n",
       "cabin_service       7.93\n",
       "food_bev           20.23\n",
       "entertainment      32.99\n",
       "ground_service     40.32\n",
       "value_for_money     2.99\n",
       "recommended         2.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the percentage of null values\n",
    "print(f'Percentage of null columns')\n",
    "round(cleandf.isna().sum()/len(cleandf)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately the column drawn to my attention is the `aircraft` column. \n",
    "\n",
    "With 70% of data being null, this is too significant to my dataset and luckily, due to the fact of this data not being relevant to my final model, I have full confidence to drop this entire column, but make sure to copy as good practise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping aircraft column\n",
    "cleandf = cleandf.drop('aircraft', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airline             0.00\n",
       "overall             2.93\n",
       "author              0.00\n",
       "review_date         0.00\n",
       "customer_review     0.00\n",
       "traveller_type     39.72\n",
       "cabin               4.01\n",
       "route              39.76\n",
       "date_flown         39.90\n",
       "seat_comfort        7.99\n",
       "cabin_service       7.93\n",
       "food_bev           20.23\n",
       "entertainment      32.99\n",
       "ground_service     40.32\n",
       "value_for_money     2.99\n",
       "recommended         2.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the percentage of null values (Iteration 1)\n",
    "print(f'Percentage of null columns')\n",
    "round(cleandf.isna().sum()/len(cleandf)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now looks a bit cleaner, but we cannot ignore the other columns which have over 30% null values and also not significant to the model.\n",
    "\n",
    "`traveller_type`: Although this may help differentiate between the type of customer, seeing as the main focus of our data is based on text, this is something I will not look into.\n",
    "\n",
    "`route`: Although one could argue, the route of the flight could impact the overall experience, the airline potentially has little no effect on the route and therefore would be classed as an external factor. This would not be useful in the model.\n",
    "\n",
    "`date_flown`: This date most likely corresponds with the data within the `review_date` column and would therefore be classified as a duplicate column, and for that reason, I can drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns not useful to the model, with a high number of null values\n",
    "cleandf = cleandf.drop(columns=['route','date_flown', 'traveller_type'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airline             0.00\n",
       "overall             2.93\n",
       "author              0.00\n",
       "review_date         0.00\n",
       "customer_review     0.00\n",
       "cabin               4.01\n",
       "seat_comfort        7.99\n",
       "cabin_service       7.93\n",
       "food_bev           20.23\n",
       "entertainment      32.99\n",
       "ground_service     40.32\n",
       "value_for_money     2.99\n",
       "recommended         2.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the percentage of null values (Iteration 2)\n",
    "print(f'Percentage of null columns')\n",
    "round(cleandf.isna().sum()/len(cleandf)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am left with still quite a few nulls, but the majority fall within columns which directly impact our target column of `recommended`. \n",
    "\n",
    "Due to these columns being based on rating but for respective categories, the most suitable solution would be to fill in the null values with the mean of each column. This will ensure a fair balance in the distribution of data (to be shown in the EDA notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values with the mean of the column\n",
    "cleandf['ground_service']= cleandf['ground_service'].fillna(cleandf['ground_service'].mean())\n",
    "cleandf['seat_comfort']= cleandf['seat_comfort'].fillna(cleandf['seat_comfort'].mean())\n",
    "cleandf['cabin_service']= cleandf['cabin_service'].fillna(cleandf['cabin_service'].mean())\n",
    "cleandf['food_bev']= cleandf['food_bev'].fillna(cleandf['food_bev'].mean())\n",
    "cleandf['entertainment']= cleandf['entertainment'].fillna(cleandf['entertainment'].mean())\n",
    "cleandf['value_for_money']= cleandf['value_for_money'].fillna(cleandf['value_for_money'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airline            0.00\n",
       "overall            2.93\n",
       "author             0.00\n",
       "review_date        0.00\n",
       "customer_review    0.00\n",
       "cabin              4.01\n",
       "seat_comfort       0.00\n",
       "cabin_service      0.00\n",
       "food_bev           0.00\n",
       "entertainment      0.00\n",
       "ground_service     0.00\n",
       "value_for_money    0.00\n",
       "recommended        2.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the percentage of null values (Iteration 3)\n",
    "print(f'Percentage of null columns')\n",
    "round(cleandf.isna().sum()/len(cleandf)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much cleaner! There are still some null values, we need to deal with these very strategically as we do not want to create any bias with our model and/or assume any patterns.\n",
    "\n",
    "There seems to be a fairly equal proportion of overall scores with the recommended column. \n",
    "\n",
    "Firstly, I will look into filling the null overall values in correspondence to where the recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a process which could affect our final model so we would need to be very careful.\n",
    "\n",
    "First, we want to create two new filtered dataframes which contain the values where the recommended column's value is `yes`, and then do the same for `no` recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df_yes = cleandf[cleandf['recommended'] == 'yes']\n",
    "filt_df_no = cleandf[cleandf['recommended'] == 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to use this filter to calculate the respective means of the `overall` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of yes recommended: 8.4\n",
      "Mean of no recommended: 2.1\n"
     ]
    }
   ],
   "source": [
    "yes_overall_mean = round(filt_df_yes['overall'].mean(),1)\n",
    "no_overall_mean = round(filt_df_no['overall'].mean(),1)\n",
    "\n",
    "print(f'Mean of yes recommended: {yes_overall_mean}')\n",
    "print(f'Mean of no recommended: {no_overall_mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fill the rows that fit the condition of; where the row is null and the recommended is `yes`/`no`, we fit the respective means.\n",
    "\n",
    "i.e. if row is null and recommended is `yes`, fill with `8.4`\n",
    "if row is null and recommended is `no`, fill with `2.1`\n",
    "\n",
    "The idea behind this approach is that, we would like to think that there is a link between the overall rating and a reason to recommend the airline, any rating between 0 and 5 is more likely to not have been recommended by a passenger, where as ratings from 6 - 10 would make sense for a positive recommendartion.\n",
    "\n",
    "Now it is worth noting that although this seems like a sensible solution, our data is reliant on individuals submitting reviews. This method could instigate some sort of speculation around whether or not a passenger would recommend an airline. The reality is, we could never 100% be confident as we do not know how the Skytrax user was feeling towards the airline at the time of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf.loc[ (cleandf['overall'].isna()) & (cleandf['recommended']=='yes'), 'overall' ] = yes_overall_mean\n",
    "cleandf.loc[ (cleandf['overall'].isna()) & (cleandf['recommended']=='no'), 'overall' ] = no_overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline            0.00\n",
       "overall            0.03\n",
       "author             0.00\n",
       "review_date        0.00\n",
       "customer_review    0.00\n",
       "cabin              4.01\n",
       "seat_comfort       0.00\n",
       "cabin_service      0.00\n",
       "food_bev           0.00\n",
       "entertainment      0.00\n",
       "ground_service     0.00\n",
       "value_for_money    0.00\n",
       "recommended        2.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(cleandf.isna().sum()/len(cleandf)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with just 20 null values, which make up 0.03% of our dataset. It is also worth mentioning that these are the values which do not meet the criteria of having a corresponding `recommended` value, therefore we can drop these rows as they are not useful to our model. \n",
    "\n",
    "Subsequently, we also have 2.29% of our `recommended` column as null values as well. We will not attempt to fill in these values as this is our target column, filling in null values would insinuate a pattern which would create bias in our final model. As a result, we would need to drop all null values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf = cleandf.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63302 entries, 0 to 65932\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   airline          63302 non-null  object \n",
      " 1   overall          63302 non-null  float64\n",
      " 2   author           63302 non-null  object \n",
      " 3   review_date      63302 non-null  object \n",
      " 4   customer_review  63302 non-null  object \n",
      " 5   cabin            63302 non-null  object \n",
      " 6   seat_comfort     63302 non-null  float64\n",
      " 7   cabin_service    63302 non-null  float64\n",
      " 8   food_bev         63302 non-null  float64\n",
      " 9   entertainment    63302 non-null  float64\n",
      " 10  ground_service   63302 non-null  float64\n",
      " 11  value_for_money  63302 non-null  float64\n",
      " 12  recommended      63302 non-null  object \n",
      "dtypes: float64(7), object(6)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#final check on final dataframe\n",
    "cleandf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.6 Checking for duplicates__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe with 63,302 entries, with no null values. For a final check, we will quickly look into duplicated rows, and if there are any, we will drop them as we should not have a case where the same author has had the same experience twice and left the exact same review for that experience. This will reduce collinearity in our model and reduce bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates : 4603\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicates : {cleandf.duplicated(subset=['customer_review', 'author']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have established 4,603 duplicate rows, and as mentioned earlier, this would create bias in our final model. Therefore, we must drop the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf = cleandf.drop_duplicates(keep='last', subset=['customer_review', 'author']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are now {cleandf.duplicated(subset=['customer_review', 'author']).sum()} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58699 entries, 0 to 65932\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   airline          58699 non-null  object \n",
      " 1   overall          58699 non-null  float64\n",
      " 2   author           58699 non-null  object \n",
      " 3   review_date      58699 non-null  object \n",
      " 4   customer_review  58699 non-null  object \n",
      " 5   cabin            58699 non-null  object \n",
      " 6   seat_comfort     58699 non-null  float64\n",
      " 7   cabin_service    58699 non-null  float64\n",
      " 8   food_bev         58699 non-null  float64\n",
      " 9   entertainment    58699 non-null  float64\n",
      " 10  ground_service   58699 non-null  float64\n",
      " 11  value_for_money  58699 non-null  float64\n",
      " 12  recommended      58699 non-null  object \n",
      "dtypes: float64(7), object(6)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# final dataframe check\n",
    "cleandf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a final dataframe which has been cleaned, with all null values dealt with appropriately and duplicates removed. This dataframe is now ready for modelling.\n",
    "\n",
    "Before we get into modelling, we will sort out the data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.7 Correcting Data Types__\n",
    "\n",
    "The main data type I can notice is the fact of our `review_date` column being an object, I will proceed to change this to `datetime` as it will ensure not only clean data, but the ability to plot visualisations to describe changes overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38903       5th August 2013\n",
       "37537    15th November 2015\n",
       "29627       20th March 2015\n",
       "10996    20th December 2016\n",
       "60934       16th April 2013\n",
       "7363     19th December 2011\n",
       "31852    14th November 2012\n",
       "57388     13th January 2016\n",
       "62093         13th May 2015\n",
       "4958        29th April 2018\n",
       "Name: review_date, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select a sample of the data from the column of interest to identify the format\n",
    "cleandf['review_date'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using python to make the conversion to datetime\n",
    "from dateutil.parser import parse\n",
    "cleandf['review_date'] = cleandf['review_date'].apply(lambda x: parse(x, fuzzy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>overall</th>\n",
       "      <th>author</th>\n",
       "      <th>review_date</th>\n",
       "      <th>customer_review</th>\n",
       "      <th>cabin</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_service</th>\n",
       "      <th>food_bev</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Christopher Hackley</td>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>london to izmir via istanbul  first time iâ  d...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Adriana Pisoi</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>stanbul to bucharest  we make our check in in ...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M Galerko</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>ome to prishtina via istanbul  i flew with thi...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Zeshan Shah</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>lew on turkish airlines iad ist khi and return...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish Airlines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pooja Jain</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>mumbai to dublin via istanbul  never book turk...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airline  overall               author review_date  \\\n",
       "0  Turkish Airlines      7.0  Christopher Hackley  2019-05-08   \n",
       "1  Turkish Airlines      2.0        Adriana Pisoi  2019-05-07   \n",
       "2  Turkish Airlines      3.0            M Galerko  2019-05-07   \n",
       "3  Turkish Airlines     10.0          Zeshan Shah  2019-05-06   \n",
       "4  Turkish Airlines      1.0           Pooja Jain  2019-05-06   \n",
       "\n",
       "                                     customer_review          cabin  \\\n",
       "0  london to izmir via istanbul  first time iâ  d...  Economy Class   \n",
       "1  stanbul to bucharest  we make our check in in ...  Economy Class   \n",
       "2  ome to prishtina via istanbul  i flew with thi...  Economy Class   \n",
       "3  lew on turkish airlines iad ist khi and return...  Economy Class   \n",
       "4  mumbai to dublin via istanbul  never book turk...  Economy Class   \n",
       "\n",
       "   seat_comfort  cabin_service  food_bev  entertainment  ground_service  \\\n",
       "0           4.0            5.0       4.0            4.0             2.0   \n",
       "1           4.0            1.0       1.0            1.0             1.0   \n",
       "2           1.0            4.0       1.0            3.0             1.0   \n",
       "3           4.0            5.0       5.0            5.0             5.0   \n",
       "4           1.0            1.0       1.0            1.0             1.0   \n",
       "\n",
       "   value_for_money recommended  \n",
       "0              4.0         yes  \n",
       "1              1.0          no  \n",
       "2              2.0          no  \n",
       "3              5.0         yes  \n",
       "4              1.0          no  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if changes have occured\n",
    "cleandf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much cleaner! Zero null values and duplicated rows, the right data types. this dataset is ready for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58699 entries, 0 to 65932\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   airline          58699 non-null  object        \n",
      " 1   overall          58699 non-null  float64       \n",
      " 2   author           58699 non-null  object        \n",
      " 3   review_date      58699 non-null  datetime64[ns]\n",
      " 4   customer_review  58699 non-null  object        \n",
      " 5   cabin            58699 non-null  object        \n",
      " 6   seat_comfort     58699 non-null  float64       \n",
      " 7   cabin_service    58699 non-null  float64       \n",
      " 8   food_bev         58699 non-null  float64       \n",
      " 9   entertainment    58699 non-null  float64       \n",
      " 10  ground_service   58699 non-null  float64       \n",
      " 11  value_for_money  58699 non-null  float64       \n",
      " 12  recommended      58699 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(7), object(5)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#final check to ensure data is ready.\n",
    "cleandf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>63853</th>\n",
       "      <th>52630</th>\n",
       "      <th>15641</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <td>Norwegian</td>\n",
       "      <td>Wizz Air</td>\n",
       "      <td>Jetblue Airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>Sally Munns</td>\n",
       "      <td>P Dalenca</td>\n",
       "      <td>Julie Graham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_date</th>\n",
       "      <td>2016-06-28 00:00:00</td>\n",
       "      <td>2018-04-27 00:00:00</td>\n",
       "      <td>2018-11-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_review</th>\n",
       "      <td>he outward and return trip from london gatwick...</td>\n",
       "      <td>luton to timisoara  horrible experience  grump...</td>\n",
       "      <td>hartford to tampa  this is the most unprofessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin</th>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Economy Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seat_comfort</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_service</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_bev</th>\n",
       "      <td>2.90817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>2.863372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.863372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ground_service</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_for_money</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommended</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             63853  \\\n",
       "airline                                                  Norwegian   \n",
       "overall                                                        2.0   \n",
       "author                                                 Sally Munns   \n",
       "review_date                                    2016-06-28 00:00:00   \n",
       "customer_review  he outward and return trip from london gatwick...   \n",
       "cabin                                                Economy Class   \n",
       "seat_comfort                                                   3.0   \n",
       "cabin_service                                                  1.0   \n",
       "food_bev                                                   2.90817   \n",
       "entertainment                                             2.863372   \n",
       "ground_service                                                 4.0   \n",
       "value_for_money                                                4.0   \n",
       "recommended                                                     no   \n",
       "\n",
       "                                                             52630  \\\n",
       "airline                                                   Wizz Air   \n",
       "overall                                                        1.0   \n",
       "author                                                   P Dalenca   \n",
       "review_date                                    2018-04-27 00:00:00   \n",
       "customer_review  luton to timisoara  horrible experience  grump...   \n",
       "cabin                                                Economy Class   \n",
       "seat_comfort                                                   1.0   \n",
       "cabin_service                                                  2.0   \n",
       "food_bev                                                       1.0   \n",
       "entertainment                                                  1.0   \n",
       "ground_service                                                 1.0   \n",
       "value_for_money                                                2.0   \n",
       "recommended                                                     no   \n",
       "\n",
       "                                                             15641  \n",
       "airline                                            Jetblue Airways  \n",
       "overall                                                        1.0  \n",
       "author                                                Julie Graham  \n",
       "review_date                                    2018-11-26 00:00:00  \n",
       "customer_review  hartford to tampa  this is the most unprofessi...  \n",
       "cabin                                                Economy Class  \n",
       "seat_comfort                                                   2.0  \n",
       "cabin_service                                                  2.0  \n",
       "food_bev                                                       1.0  \n",
       "entertainment                                             2.863372  \n",
       "ground_service                                                 1.0  \n",
       "value_for_money                                                2.0  \n",
       "recommended                                                     no  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect a sample of the data for better viewability\n",
    "cleandf.sample(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.8 Creating Features__\n",
    "\n",
    "Create a `Year` and `Month` column\n",
    "\n",
    "I now want to extract the year and month from the `review_date` column so it can be treated as numerical data for the purpose of modelling and precise analysis.\n",
    "\n",
    "I will only pull the years and months and not the days as it will be too specific to plot and might cause confusion. \n",
    "\n",
    "The reason for this is that I would be able to identify trend patterns over time which cann also help pin point anomalies i.e. where there was an unexpected dip in the number of positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting year and month from date and creating new columns\n",
    "cleandf['review_year'], cleandf['review_month'] = cleandf['review_date'].dt.year, cleandf['review_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping original release_date column to avoid multicolliniearity \n",
    "cleandf = cleandf.drop(columns=['review_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_year  review_month\n",
       "0         2019             5\n",
       "1         2019             5\n",
       "2         2019             5\n",
       "3         2019             5\n",
       "4         2019             5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View new columns\n",
    "cleandf[['review_year','review_month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1.9 Saving Work__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataframe now looks good and ready for analysis. I will now save this work into a .pkl file and continue to my exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline', 'overall', 'author', 'customer_review', 'cabin',\n",
       "       'seat_comfort', 'cabin_service', 'food_bev', 'entertainment',\n",
       "       'ground_service', 'value_for_money', 'recommended', 'review_year',\n",
       "       'review_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/cleandf.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save data as .pkl file in the data folder, following the same file directory.\n",
    "joblib.dump(cleandf, '../data/cleandf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Ending Summary**\n",
    "\n",
    "In this notebook, I have completed some data cleaning to ensure the data is of its highest quality before analysis and processing may occur. This will give the most accurate analysis, and thus more accurate findings.\n",
    "\n",
    "In the next notebook, I will be exploring my cleaned data by doing eploratory data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faisal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
